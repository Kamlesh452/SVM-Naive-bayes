{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a Support Vector Machine (SVM)?"
      ],
      "metadata": {
        "id": "WmH9RuCl5gli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> A Support Vector Machine (SVM) is a type of supervised machine learning algorithm used mostly for classification tasks (though it can also handle regression). Its main job is to find the best possible boundary (called a hyperplane) that separates data points of different classes."
      ],
      "metadata": {
        "id": "rDXaeVtf5nBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the difference between Hard Margin and Soft Margin SVM?"
      ],
      "metadata": {
        "id": "JivnzVA6oQSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>>It allows some data points to be within the margin or even misclassified if that helps improve the overall model performance."
      ],
      "metadata": {
        "id": "m4D7yh7IolkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the mathematical intuition behind SVM?"
      ],
      "metadata": {
        "id": "InhIIALWpAWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> At its core, an SVM tries to find a hyperplane (a decision boundary) that maximizes the margin between two classes.\n",
        "The margin is the distance between the hyperplane and the nearest data points from each class (called support vectors).\n",
        "\n",
        "The goal is to find the hyperplane that leaves the widest possible gap while still correctly classifying the data."
      ],
      "metadata": {
        "id": "b9g7jztkpG8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the role of Lagrange Multipliers in SVM?"
      ],
      "metadata": {
        "id": "KfazB67opRSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> When optimizing SVM’s objective function (like minimizing\n",
        "1\n",
        "2\n",
        "∣\n",
        "∣\n",
        "𝑤\n",
        "∣\n",
        "∣\n",
        "2\n",
        "2\n",
        "1\n",
        "​\n",
        " ∣∣w∣∣\n",
        "2\n",
        " ) with constraints (like ensuring all data points are correctly classified relative to the margin), we need a way to handle those constraints mathematically while still optimizing the function.\n",
        "\n",
        "That’s where Lagrange multipliers come in.\n",
        "They let us combine the objective function and the constraints into a single function called the Lagrangian, making it possible to solve the problem using optimization techniques.\n",
        "\n"
      ],
      "metadata": {
        "id": "jwVoaLzcpXcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are Support Vectors in SVM?"
      ],
      "metadata": {
        "id": "ZGM9-rmxpmBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> In an SVM model, support vectors are the data points that lie closest to the decision boundary (hyperplane).\n",
        "They are the most important points in the dataset because they:\n",
        "\n",
        "Directly determine the position and orientation of the hyperplane\n",
        "\n",
        "Define the margin width between the two classes.\n",
        "\n",
        "If you removed these points and retrained the SVM, the position of the decision boundary would likely change.\n",
        "In contrast, points far from the margin don’t affect the boundary at all."
      ],
      "metadata": {
        "id": "rF7IjDDfqN-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is a Support Vector Classifier (SVC)?"
      ],
      "metadata": {
        "id": "7nZ4B6SgqYfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> A Support Vector Classifier (SVC) is essentially the practical implementation of a soft-margin Support Vector Machine (SVM) for classification tasks.\n",
        "\n",
        "It’s what people typically mean when they say \"SVM\" in the context of classification, especially when using libraries like scikit-learn in Python."
      ],
      "metadata": {
        "id": "Artwt7Czqdjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is a Support Vector Regressor (SVR)?"
      ],
      "metadata": {
        "id": "pYwn0tMkqm57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> Support Vector Regression (SVR) is a type of Support Vector Machine (SVM) that’s used for predicting continuous values, instead of classifying categories.\n",
        "\n",
        "While SVM classification tries to find a hyperplane that separates data points into classes, SVR tries to find a function (like a line or curve) that predicts continuous output values, while staying as close as possible to the actual data points — within a certain allowable margin of error.\n",
        "\n"
      ],
      "metadata": {
        "id": "6ynIASKfqthD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the Kernel Trick in SVM?"
      ],
      "metadata": {
        "id": "BcuONx0urAgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> The kernel trick is a mathematical technique that allows Support Vector Machines (SVM) to solve non-linear classification or regression problems by implicitly mapping data into a higher-dimensional space without explicitly computing the coordinates in that space."
      ],
      "metadata": {
        "id": "W-fSfPDsrF1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Compare Linear Kernel, Polynomial Kernel, and RBF Kernel."
      ],
      "metadata": {
        "id": "-RpjLSh5rQsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>>Linear Kernel: Simple and fast. Use it when data is clearly linearly separable.\n",
        "\n",
        "Polynomial Kernel: Medium complexity. Use it when you suspect polynomial relationships.\n",
        "\n",
        "RBF Kernel: Very flexible. Use it when data is messy, non-linear, or you have no idea about the underlying relationship.\n",
        "\n"
      ],
      "metadata": {
        "id": "5jT_FbdnrZdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the effect of the C parameter in SVM?"
      ],
      "metadata": {
        "id": "dWzMpuNUrqqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>>  is the regularization parameter in SVM that controls the trade-off between:\n",
        "\n",
        "Maximizing the margin between classes (making the decision boundary as wide as possible)\n",
        "vs.\n",
        "\n",
        "Allowing classification errors (misclassifying some points)\n",
        "\n",
        "In simpler terms:\n",
        "\n"
      ],
      "metadata": {
        "id": "0nHoldRCryMI"
      }
    }
  ]
}